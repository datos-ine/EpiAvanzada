---
title: "**Estudios de cohortes**"
format: html
editor: visual
toc: true
toc-title: "Contenidos"
theme: "../../custom.scss"
bibliography: references.bib
nocite: |
  @nolasco2016, @pérezhoyos2001, @salinas-rodríguez2009, @RCoreTeam2021, @tidyverse, @performance, @gtsummary
---

```{r}
#| echo: false

knitr::opts_chunk$set(message = F, warning = F,
                      fig.align = "center", dpi = 300)

### Carga paquetes
pacman::p_load(
  flextable,
  tidyverse
)

### paleta colorblind
pal <- scico::scico(n = 12, palette = "navia")
```

[Este material es parte de la]{.text style="display: block; text-align: center;"}**Unidad 5 del Curso de Epidemiología - Nivel Avanzado del Instituto Nacional de Epidemiología “Dr. Juan H. Jara” - ANLIS**

[Estudios de cohortes by [Andrea Silva, Christian Ballejo y Tamara Ricardo](http://www.ine.gov.ar/) is licensed under [CC BY-NC 4.0](http://creativecommons.org/licenses/by-nc/4.0/?ref=chooser-v1) ![](data:image/svg+xml;base64,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){width="20"}![](data:image/svg+xml;base64,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){width="20"}![](data:image/svg+xml;base64,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){width="20"}]{.text style="display: block; text-align: center;"}

## Introducción

En su concepción más simple, un diseño de cohorte implica la selección de un grupo de personas expuestas al factor de estudio y la selección de un grupo similar, pero sin la exposición, considerado como no expuesto. El seguimiento de ambos grupos se pautará para un lapso determinado, y se evaluará en dicho período si se produjo o no el evento de interés. Finalmente se realiza una comparación entre ambos grupos.

La esencia de los estudios de cohortes es el seguimiento. Por tratarse de estudios longitudinales, los mismos podrán ser prospectivos, retrospectivos o mixtos. La cohorte podrá ser una cohorte fija o dinámica. En las primeras, se fija un período de reclutamiento de participantes y una vez finalizado dicho período, no se incluyen más sujetos para el seguimiento. En una cohorte abierta, o dinámica, se permite el ingreso y egreso de participantes en toda la extensión del estudio.

Como recordarán, los criterios de selección están en la exposición, por lo cual la misma debe estar claramente definida. Como dijimos anteriormente, la idea clásica de un estudio de cohorte es comparar dos grupos, expuestos y no expuestos. Pero los grupos de referencia pueden ser otros:

-   **Estudios de comparación con la población general**: El estudio identifica y sigue a una determinada cohorte de exposición. La frecuencia de aparición de la enfermedad en dicha cohorte es comparada con la observada en la población general. Para ello es necesario disponer de registros poblacionales que suministren dicha información.

-   **Comparaciones internas**: La cohorte a estudio supone una mezcla de personas expuestas y no expuestas. Las comparaciones se realizan dentro de la propia cohorte.

Por otra parte, el evento a observar puede tomar distintas formas: puede tratarse de un evento fijo, eventos múltiples, cambio en una medida de función (la cual se evalúa mediante tasa de cambio) o marcadores intermedios del evento, esto también impactará en la forma de análisis.

A la hora de diseñar un estudio de cohortes es importante, entonces, definir de forma clara los siguientes aspectos:

-   Criterios de inclusión
-   Fecha de entrada y de salida de los participantes en el estudio
-   Seguimiento
-   Eventos finales de interés
-   La exposición
-   Factores de confusión
-   Consideraciones éticas
-   Estrategias de análisis
-   Potencia estadística

En la siguiente tabla se remarcan ventajas y desventajas de estos estudios:

```{r}
#| echo: false
#| message: false
#| tbl-cap: "Tabla 1. ventajas y desventajas de los estudios de cohorte."

### Genera tabla
tibble(
  Ventajas = c(
  "Más cercanos a un experimento",
  "La relación temporal causa efecto es verificable", 
  "Se pueden estimar medidas de incidencia", 
  "Eficientes para evaluar exposiciones poco frecuentes",
  "Se pueden estudiar varios eventos",
  "Se pueden fijar criterios de calidad en la medición del evento",
  "Bajo riesgo de sesgo de selección (en especial en estudios prospectivos)"),
  Desventajas = c(
         "Cuando se trata de eventos poco frecuentes la complejidad y el costo pueden aumentar considerablemente",
         "Requiere estudiar y seguir un número grande de participantes",
         "Son estudios difíciles de realizar",
         "", "", "", ""
       )) |> 
  flextable() |> 
  
  ### Formato tabla
  font(fontname = "Helvetica", part = "all") |> 
  fontsize(size = 12, part = "all") |> 
  bold(part = "header") |> 
  bg(bg = pal[6], part = "header") |> 
  color(color = "white", part = "header") |> 
  set_table_properties(layout = "autofit")
```

### ¿Cómo analizar un estudio de cohortes?

Seguramente ustedes recordarán de otros cursos de epidemiología, que en su forma más simple, podemos calcular Riesgos Relativos (RR) en un estudio de cohortes. Vamos a profundizar otros aspectos de este diseño.

El análisis de los estudios de cohortes ha de tener en cuenta la variable tiempo. La existencia de pérdidas de participantes por diferentes motivos y la diferente duración del seguimiento de los distintos miembros de la cohorte, implican la necesidad de técnicas analíticas especiales que, a la vez, permitan considerar toda la información aportada por los integrantes de la cohorte. Existen dos estrategias diferentes de análisis en los estudios de cohortes: el análisis supervivencia y el análisis personas-tiempo, pero ambas requieren disponer de información precisa sobre el inicio y el final del seguimiento de cada participante y conocer el status del participante en el momento de finalización o salida del estudio (desarrollo o no el evento de interés). Asimismo será necesario definir una escala temporal adecuada.

La estrategia de **análisis de supervivencia**, la abordaremos en la próxima unidad, de la mano de los estudios experimentales, pero tengan presente que la podemos emplear en cualquier estudio de cohorte, que contemos con la información puntualizada anteriormente.

Las técnicas de **personas-año** utilizan como unidad de análisis estratos o grupos homogéneos en los que es razonable asumir una misma tasa de incidencia. Las técnicas clásicas de análisis “personas tiempo” incluyen la comparación de tasas, la estandarización directa y las razones estandarizadas de incidencia o mortalidad (denominadas en la literatura RIE o SIR, para la incidencia y RME o SMR para la mortalidad). RIE y RME comparan el número de casos observados con el número esperado teniendo en cuenta la frecuencia de enfermedad en la población utilizada como referencia. La técnica multivariada por excelencia para la modelización de las tasas es la regresión de Poisson, que utiliza la distribución de Poisson para modelizar la variabilidad aleatoria del numerador de las tasas y es lo que aprenderemos en este capítulo.

A modo de resumen, compartimos esta tabla, extraída del libro de @hernández-ávila2011:

```{r}
#| echo: false
#| message: false
#| tbl-cap: "Tabla 1. ventajas y desventajas de los estudios de cohorte."

### Genera tabla
tibble(
  Aspecto = c(
    "Tamaño de la muestra",
    "Tipo de eventos",
    "Escala temporal",
    "Tipos de medida",
    "Análisis bivariado", "", "",
    "Análisis multivariado"
  ),
  `Análisis de supervivencia` = c(
    "Relativamente pequeño",
    "Frecuentes",
    "Única",
    "Probabilidad (condicional y acumulada)",
    "Comparación de curvas de supervivencia",
    "Log-rank test",
    "Razón de riesgos",
    "Regresión de Cox"
  ),
  `Análisis basado en tiempo-persona` = c(
    "Relativamente grande",
    "Raros",
    "Única o múltiple",
    "Tasa (densidad)",
    "Comparación de tasas",
    "Razón de tasas",
    "REM",
    "Regresión de Poisson"
  )) |> 
  flextable() |> 
  
  ### Formato tabla
  font(fontname = "Helvetica", part = "all") |> 
  fontsize(size = 12, part = "all") |> 
  bold(part = "header") |> 
  bg(bg = pal[6], part = "header") |> 
  color(color = "white", part = "header") |> 
  set_table_properties(layout = "autofit")
```

## Regresión de Poisson

La distribución de Poisson es una distribución que modeliza bien situaciones de conteo. Por ejemplo: números de accidentes, número de personas que tienen un infarto, número de personas que asisten a una consulta, número de hijos, etc. La característica es que son números finitos, no muy grandes, siempre positivos. Los mismos transcurren dentro de un intervalo, habitualmente de tiempo, pero también se puede considerar intervalos de población. Es decir que busca modelar el número de veces en que ocurre un evento en un intervalo determinado.

La distribución de Poisson toma, pues, valores enteros no negativos: 0, 1, 2, 3, 4... La distribución de Poisson tiene un único parámetro, lambda ($\lambda$), que coincide con la Esperanza y la Varianza de la distribución. O sea, es una distribución que cuanto más grande es el valor esperado más dispersión tienen los valores.

Vamos a entender cómo se aplica la regresión de Poisson en el marco de un estudio de cohortes. Supongamos entonces que tenemos un estudio de cohortes clásico, con dos grupos de comparación: un grupo expuesto y otro no expuesto. Para cada grupo se dispone el número de eventos ($d$) y la cantidad de personas-tiempo seguidas ($n$). Como recordarán, la tasa de incidencia ($\lambda$), la podemos calcular como el cociente:

$$\lambda = \frac{d}{n}$$ Se asume que el número de eventos observados en cada grupo sigue una distribución de Poisson, con un valor esperado igual al producto de la tasa de incidencia por las personas tiempo. $E(d)= \lambda*n$. Así, la probabilidad de observar $d$ eventos, sería:

$$
P(x=d)= \frac{(\lambda n)^d e^{-\lambda n}}{d} 
$$

Omitiendo el desarrollo matemático, la modelización de la regresión de Poisson consiste en establecer un modelo de efectos lineales de distintas covariables sobre el logaritmo de la tasa del subgrupo correspondiente.En general, el modelo de Poisson se expresa como:

$$
ln\lambda = \alpha+\beta_1x_1+\beta_2x_2+\dots+\beta_nx_n \qquad (*)
$$

En forma equivalente, podemos decir:

$$
\lambda=e^{\beta_0+\beta_1x_1+\dots+\beta_nx_n}
$$ Si operamos en forma análoga a lo que hicimos en la regresión logística, concluiremos que los parámetros del modelo son interpretables a través de potencias de base $e$ como riesgos relativos (cocientes de tasas). La expresión formal es:

$$
RR_{x*/x}=e^{\sum^k_i=1\beta_i(x^*_i-x_i)}=\prod^k_{i=1}e^{\beta_i(x^*_i-x_i)}
 $$ El símbolo $\prod$ significa productoria. Se simboliza con la letra Pi en mayúscula e implica una secuencia de productos.

Nuevamente, si volvemos a la ecuación:

$$
\lambda = \frac{d}{n}
$$

Entonces, si aplicamos logaritmo natural:

$$
ln\lambda=ln \frac{d}{n}=ln(d)-ln(n)
$$ Si igualamos con (\*)

$$
ln\lambda=\alpha+\beta_1x_1+\beta_2x_2+\dots+\beta_nx_n
$$ $$
ln(d)=ln(n)+\alpha+\beta_1x_1+\beta_2x_2+\dots+\beta_nx_n 
$$ Al término $ln(n)$ se lo llama ***offset***. En general, es un valor que debemos darle al software para que ajuste un modelo de Poisson, no se estima a partir de los datos.

Ahora que tenemos la ecuación del modelo, será necesario estimar los coeficientes y luego evaluar la calidad del ajuste.

Los coeficientes se calculan utilizando métodos como la Estimación de máxima verosimilitud (MLE). A partir de los coeficientes que nos produce la estimación de máximo-verosimilitud podemos realizar las siguientes inferencias: el test de Wald, para testear la $H_0 : β_i=0$, sus IC, y de ahí calcular los RR, con sus respectivos IC.

La bondad de ajuste del modelo se evaluará a través de la función Deviance siguiendo el mismo esquema jerárquico de evaluación que en el caso de la regresión logística

### Supuestos del modelo de Poisson

Como dijimos, la idea de Poisson es contar eventos en intervalos de tiempo o de población (también podría ser espacial). La variable respuesta toma valores positivos. Depende de un solo parámetro: $\lambda$. La distribución de Poisson tiene iguales la media y la varianza. Este es un supuesto muy importante de este modelo, y se conoce como supuesto de **equidispersión**. Si la variación de los casos observados en una población excede a la variación esperada por Poisson, se está ante la presencia de un problema conocido como **sobredispersión** y, en tal caso, existen distribuciones más adecuadas como la binomial negativa, la Conway-Maxwell Poisson o las distribuciones *quasi* (que no abordaremos aquí).

Los principales supuestos de Poisson son:

-   Las observaciones deben ser independientes.
-   El parámetro $\lambda$ debe ser constante a lo largo del tiempo: esto se garantiza si se cumple con el principio de equidispersión.
-   La cantidad de eventos en un intervalo es proporcional al tamaño del intervalo
-   Dos o más eventos no pueden ocurrir en un mismo momento puntual

En la práctica, no siempre se cumple el principio de equidispersión, y lo más frecuente es la sobredispersión, es decir que la varianza sea superior a la media. Esto conduce a sesgos en la estimación de los desvíos estándares de los coeficientes. Por eso es importante diagnosticar la sobredispersión. *Lindsay* propone aplicar el coeficiente de variación (CV) como indicador para evaluar sobredispersión. El CV se define como el cociente entre la varianza estimada y la media estimada. Otros autores sugieren otros indicadores, veremos en el ejemplo como podemos evaluar sobredispersión en R.

Otras situaciones en las cuales el modelo de Poisson no es adecuado es cuando existe un número excesivo de ceros, esto es, una frecuencia observada de ceros que no es consistente con el modelo Poisson. Esto se debe a que el $ln(0)$ no está definido. Como se señaló previamente, si bien es cierto que el modelo binomial negativo se ha desarrollado para modelar la heterogeneidad no observada, también es cierto que esa misma heterogeneidad es originada por un número excesivo de ceros. De manera particular, es posible que el mecanismo aleatorio que dio origen a los datos de conteo muestre una mayor concentración para algún valor específico, que puede ser el cero (como ocurre con algunas variables vinculadas a salud) o cualquier otro valor positivo. Esto implica que dicho valor tiene una mayor probabilidad de ocurrencia que la especificada por la distribución Poisson o cualquier otra distribución. En estos casos, se suele utilizar un modelo para datos de conteo cero-inflado (*zero-inflated* Poisson o *zero-inflated* binomial negativa), que le confiere mayor peso a la probabilidad de que la variable de conteo sea igual a cero.

## Aplicación en R

La regresión de Poisson se encuentra implementada en lenguaje R como otro de los modelos de la familia de modelos lineales generalizados (GLM de las siglas en inglés de *Generalized Linear Models*) similar a la regresión logística vista en la unidad anterior.

Un criterio importante en la elección de la función de enlace para varias familias de distribuciones es asegurar que los valores ajustados del modelado permanezcan dentro de límites razonables. La especificación de un enlace logarítmico (predeterminado para Poisson) garantiza que los recuentos ajustados sean todos mayores o iguales a cero (propio de los conteos).

Por lo tanto, en este caso el ajuste tiene errores de Poisson y la función de enlace para linealizar la relación entre la variable respuesta y la(s) variable(s) independiente(s) es el `log`.

### Construcción de un modelo de regresión de Poisson en R

Como es de imaginar utilizaremos la misma función general `glm()`, cambiando los argumentos en familia y enlace.

La sintaxis básica de esta función, contenida en el paquete `stats` de R `base`, es:

$$
glm(formula, family = poisson(link = "log"), data)
$$

o lo mismo si omitimos el enlace, dado que el valor `log` es el predeterminado para esta familia.

$$
glm(formula, family = poisson, data)
$$

donde:

`formula`: al igual que en la regresión logística o lineal, es la fórmula que describe el modelo a ajustar. Sigue la estructura:

$$
variable\_dependiente \sim variable\_indepen_1 + variable\_indepen_2 +\dots+ variable\_indepen_n
$$

`family`: hace referencia a la familia de distribuciones y, en `link`, a la función de enlace elegida para el ajuste de este modelo.

`data`: indica el nombre de la base de datos (dataframe) que contiene las variables del modelo.

La salida de resultados de esta función puede obtenerse a través de la función `summary()` al igual que en las otras regresiones vistas. La sintaxis es `summary(nombre_modelo)`, siendo `nombre_modelo` el nombre del modelo ajustado.

La resultados del objeto de regresión de Poisson mostrados están compuesto por:

**Call**: fórmula del modelo

**Deviance Residuals**: distribución de los residuos (mediana, mínimo, máximo y percentilos 25-75) obtenidos en la última iteración

**Coefficients**: coeficientes del intercepto y los asociados a cada variable independiente. Además se agregan los errores estándar y el valor z (*estadístico de Wald* que surge del cociente entre el coeficiente y su error estándar) con el p-valor correspondiente.

**Dispersion parameter for poisson family taken to be 1**: Significa que el modelo asume el supuesto de igualdad entre la media y la varianza (dispersión = 1)

**Null deviance**: devianza para el modelo nulo que solo contiene la constante.

**Residual deviance**: devianza del modelo ajustado.

**AIC**: criterio de información de Akaike.

**Number of Fisher Scoring iterations**: cantidad de iteraciones.

Este resumen surge del *objeto de regresión* construido cuando asignamos la salida de la función `glm()` que pertenece a la clase "glm" y "lm".

El objeto de regresión está compuesto por 30 componentes que pueden accederse a través del nombre del modelo seguido del signo `$` y el nombre del componente.

Entre los componentes más relevantes podemos señalar (usamos *nombre_modelo* como generalización del nombre del objeto creado):

`nombre_modelo$coeficients`: vector de coeficientes del modelo. También se puede obtener a través de la función `coef(nombre_modelo)`

`nombre_modelo$residuals`: vector que contiene los residuos obtenidos en la última iteración.

`nombre_modelo$fitted.values`: vector con los valores medios ajustados, obtenidos según la transformación de los predictores lineales por la inversa de la función de enlace.

`nombre_modelo$family`: devuelve la familia utilizada en la construcción del modelo.

`nombre_modelo$deviance`: devianza del modelo ajustado o -2 veces el máximo de la log verosimilitud.

`nombre_modelo$aic`: criterio de información de Akaike (AIC)

`nombre_modelo$null.deviance`: devianza para el modelo nulo que solo contiene la constante.

### Ejemplo práctico

A fin de mostrar las funciones y la metodología de análisis con R vamos a utilizar datos que se tomaron de un estudio de cohorte ocupacional realizado para probar la asociación entre las muertes respiratorias y la exposición al arsénico en la industria, después de ajustar por varios otros factores de riesgo.

La variable principal es `muertes`. Este es el número de muertes por persona-años (`persona_anio`) de sujetos en cada categoría, por lo que finalmente nos interesa la tasa de incidencia (`mortalidad`) como variable resultado.

Las otras variables son covariables independientes que incluyen el grupo de edad `grupo_edad`, el período de empleo `periodo`, el año de inicio del empleo `comienzo` y el nivel de exposición al arsénico durante el período de estudio `arsenico`.

Activemos paquetes y leamos los datos:

```{r}
#| message: false
#| warning: false

### Carga paquetes
# chequeo de supuestos
library(performance)

# tablas regresión
library(gtsummary)

# formato de tablas
library(flextable)

# manejo de datos
library(tidyverse)

### Carga datos
datos <- read_csv2("cohorte_ocupacional.txt")

### Explora datos
glimpse(datos)

```

Las variables `grupo_edad`, `periodo`, `comienzo` y `arsenico` son categóricas y debemos convertirlas a factor. Podemos hacer esto variable por variable o usando el comando `across()` dentro de `mutate()`:

```{r}
### Transformo a factor
datos <- datos |> 
  mutate(across(grupo_edad:arsenico, .fns = ~ as.factor(.x)))
```

Revisemos los niveles de cada factor:

```{r}
# grupo etario
levels(datos$grupo_edad)

# periodo
levels(datos$periodo)

# comienzo
levels(datos$comienzo)

# arsenico
levels(datos$arsenico)
```

Exploremos los datos de la base organizando la información de persona-años por edad y período. Transformaremos la salida en una tabla usando las funciones `flextable()` y `autofit()` del paquete `flextable`.

```{r}
## Creo tabla
datos  |>  
  count(periodo, grupo_edad, wt = persona_anio) |> 
  pivot_wider(names_from = grupo_edad, values_from = n) |>
  
  # formato de tabla
  flextable() |> 
  autofit()
```

Ahora hacemos lo mismo para el número de muertes y calculamos la incidencia por 10000 personas-año para cada celda:

```{r}
## Creo objeto para personas-años
personas_años <- datos |> 
  count(periodo, grupo_edad,
        wt = persona_anio,
        name = "p.a")

### Creo tabla
datos |> 
  count(periodo, grupo_edad, wt = muertes) |> 
  left_join(personas_años) |> 
  mutate(incidencia = round(n/p.a*10000,2)) |> 
  select(-n, -p.a) |> 
  
  # formato de tabla
  flextable() |> 
  autofit()
```

Podemos verlo mejor en un gráfico, por razones de extensión omitiremos el código, pero si tienen interés pueden solicitarlo al equipo docente:

```{r}
#| echo: false
### Creo tabla
datos |> 
  count(periodo, grupo_edad, wt = muertes) |> 
  left_join(personas_años) |> 
  mutate(incidencia = round(n/p.a*10000,2)) |> 
  select(-n, -p.a) |> 
  
  ## Creo gráfico
  ggplot(aes(x = periodo, y = incidencia, 
             color = grupo_edad, group = grupo_edad)) +
  geom_point() +
  geom_line() +
  labs(title = "Incidencia de muertes (mortalidad) por edad y período") +
  scale_color_brewer(palette = "Set2", name = "Edad") +
  xlab(label = "Período") +
  ylab(label = "10.000 personas-año") +
  theme_minimal()


```

Este gráfico muestra, como es esperable, que el grupo de mayor edad generalmente se asocia con un mayor riesgo de morir, pero necesitamos ajustar los efectos de las demás covariables para examinar mejor esta relación.

Dado que en este ejemplo nos interesa modelar la tasa de incidencia vamos a necesitar incorporar dentro del modelo un termino de desplazamiento (en inglés *"offset"*).

Creamos el modelo saturado para trazar iteraciones *backward*.

```{r}
modelo <- glm(muertes ~ periodo + grupo_edad + arsenico, offset = log(persona_anio),
              family = poisson,
              data = datos)
```

El término `offset = log(persona_anio)` permite que la variable `persona_anio` sea el denominador de los recuentos de `muertes`. Se necesita una transformación logarítmica ya que, para un modelo lineal generalizado de Poisson, la función enlace es el log.

Veamos la salida resumen del modelo:

```{r}
summary(modelo)
```

Este primer modelo con todas las covariables muestra como significativos a casi todos los niveles de las variables respecto a las referencias.

Un problema del ajuste de la regresión de Poisson, es el no cumplimiento del supuesto "media es igual a la varianza". Generalmente se presente en forma de dispersión excesiva y a veces insuficiente, donde la varianza es mayor o menor que el valor medio, respectivamente.

Podemos probar la bondad de ajuste del modelo en función de la significancia de la sobredispersión de los errores de un modelo de Poisson, aplicando la función `check_overdispersion()` del paquete `performance`.

```{r}
check_overdispersion(modelo)
```

El componente `Pearson's Chi-Squared` se calcula a partir de la deviance del modelo. Cómo toda prueba de bondad de ajuste buscamos que *p* sea mayor a 0,05.

Por ahora el valor de *p* indica un buen ajuste.

Ahora probamos quitar de a una variable en la primer tanda iterativa.

```{r}
# (-) arsénico
mod1 <- glm(muertes ~ periodo + grupo_edad, 
            offset = log(persona_anio),
              family = poisson,
              data = datos)

# (-) grupo etario
mod2 <- glm(muertes ~ periodo + arsenico, 
            offset = log(persona_anio),
              family = poisson,
              data = datos)
         
# (-) periodo
mod3 <- glm(muertes ~ grupo_edad + arsenico, 
            offset = log(persona_anio),
              family = poisson,
              data = datos)      
```

Para comparar performance podemos usar `compare_perfomance()` del paquete `performance`.

```{r}
compare_performance(mod1, mod2, mod3, metrics = "common")
```

Buscamos el menor AIC, que en este caso es `mod3` (modelo con variables `grupo_edad` y `arsenico`)

En la segunda fase de iteración partimos de este modelo y quitamos otra variable, lo que signica en nuestro ejemplo construir regresiones simples:

```{r}
# (-) arsénico
mod4.1 <- glm(muertes ~ grupo_edad, 
              offset = log(persona_anio),
              family = poisson,
              data = datos) 

# (-) grupo etario
mod4.2 <- glm(muertes ~ arsenico, 
              offset = log(persona_anio),
              family = poisson,
              data = datos) 
```

Volvemos a comparar:

```{r}
compare_performance(mod3, mod4.1, mod4.2, metrics = "common")
```

El mejor modelo continúa siendo `mod3`, por lo que vamos a probar su bondad de ajuste:

```{r}
check_overdispersion(mod3)
```

El *p* valor del test confirma un buen ajuste.

Procedemos a chequear significancia de las variables explicativas:

```{r}
summary(mod3)
```

Todos los niveles de las variables son significativos respecto a sus niveles de referencia.

```{r}
tbl_regression(mod3, exponentiate = T)
```

Traducidos a riesgo, mediante la exponenciación de los coeficientes, observamos que los diferentes categorías de años de exposición al arsénico no varían entre sí. Esto nos hace pensar que puede valer la pena agruparlo en solo dos niveles.

```{r}
## Recategoriza arsénico
datos <- datos %>% 
  mutate(arsenico_cat = if_else(
    arsenico == "<1 año", "<1 año", "1+ años") |> 
      as.factor())

## Modelo con arsénico recategorizado
mod5 <- glm(muertes ~ grupo_edad + arsenico_cat,
                offset = log(persona_anio), 
               family = poisson, 
               data = datos)

## Compara modelos
compare_performance(mod3, mod5, metrics = "common")
```

El `mod5` tiene mejor *performance* que el modelo anterior.

```{r}
check_overdispersion(mod5)
```

El ajuste continúa siendo bueno.

Chequeamos significancia:

```{r}
summary(mod5)
```

Las variables incluídas son significativas.

En esta etapa, aceptaríamos el `mod5` como el mejor modelo, ya que tiene el AIC más pequeño entre todos los modelos que hemos probado.

```{r}
tbl_regression(mod5, exponentiate = T)
```

Concluimos que aquellas personas expuestas al arsénico durante al menos un año, tienen 2,25 veces mayor riesgo de muerte por enfermedad respiratoria.

Expliquemos de donde deriva este cálculo. En los modelos de Poisson de este tipo, la estructura de la compensación (*offset*) definida como **log(persona-tiempo)** convierte al resultado en **log(densidad de incidencia)**.

La tabla creada al comienzo del ejemplo proporciona la densidad de incidencia bruta por grupo de edad y período. Cada uno de los modelos de regresión de Poisson anteriores se puede utilizar para calcular la densidad de incidencia prevista cuando se dan las variables del modelo. Por ejemplo, para calcular la densidad de incidencia de una población de 100.000 personas de entre 40 y 49 años que estuvieron expuestas al arsénico durante menos de un año utilizando `mod5`, podemos ejecutar:

```{r}
## Genera nuevos datos
newdata <- tibble(grupo_edad = "40-49",
                  arsenico_cat = "<1 año",
                  persona_anio = 100000)

## Predice datos
predict(object = mod5, newdata = newdata, type = "response") 
```

Esta población tendría una densidad de incidencia estimada de 33,26 por 100.000 personas-año.

En un estudio de casos y controles, como los vistos en la Unidad 4, el OR se utiliza para comparar la prevalencia de exposición entre casos y controles. En un estudio de cohorte, este valor es igual a la relación entre las probabilidades de contraer una enfermedad entre el grupo expuesto y el no expuesto. La razón de los riesgos para los dos grupos se denomina entonces "razón de riesgo" o "riesgo relativo".

En un estudio de cohorte real, los sujetos no siempre tienen la misma duración de seguimiento. El riesgo relativo ignora la duración del seguimiento. Por tanto, no es una buena medida de comparación del riesgo entre los dos grupos.

En este ejercicio, todos los sujetos agrupan sus tiempos de seguimiento y este número se denomina "tiempo-persona", que luego se utiliza como denominador del evento, lo que da como resultado una "densidad de incidencia".

Comparar la densidad de incidencia entre dos grupos de sujetos por su estado de exposición es más justo que comparar los riesgos crudos. La relación entre las densidades de incidencia de dos grupos se denomina razón de densidades de incidencia (RDI), que es una forma mejorada de riesgo relativo.

En el `mod5`, para calcular la razón de densidad de incidencia entre los sujetos expuestos al arsénico durante uno o más años frente a los expuestos durante menos de un año, podemos dividir la incidencia entre los primeros por la del segundo grupo.

```{r}
## Genera nuevos datos
newdata <- tibble(grupo_edad = rep("40-49", 2),
                  arsenico_cat = c("<1 año", "1+ años"),
                  persona_anio = rep(100000, 2))

## Densidad de incidencia
di <- predict(object = mod5, newdata = newdata, type = "response") 

## Razón densidad de incidencia
rdi.arsenico <- di[2] / di[1]

rdi.arsenico
```

El código anterior comienza agregando una nueva fila al dataframe `newdata` que tiene lo mismo que la primera fila, excepto que la variable `arsenico_cat` es `"1+ años"`.

A continuación, se calculan las respuestas o densidades de incidencia de las dos condiciones.

La RDI se obtiene luego de la división de las densidades de incidencia para `arsenico_cat = "<1 año"` con `arsenico_cat = "1+ años"`. Una forma más corta de obtenerla es mediante el coeficiente de la variable específica `arsenico`, utilizando R `base` o el paquete `gtsummary`.

```{r}
tbl_regression(mod5, exponentiate = T,
               include = "arsenico_cat")
```

También podemos mostrar la salida mediante un gráfico de `ggplot2`, tal como vimos en la unidad 4:

```{r}
## Convierte la salida del modelo a dataframe
mod5_df <- mod5 %>% 
  broom::tidy(exponentiate = T, conf.int = T) 

## Genero gráfico
mod5_df %>% 
     ggplot(mapping = aes(x = estimate, y = term,
                xmin = conf.low, xmax = conf.high)) +
  
  # añade línea vertical
  geom_vline(xintercept = 1, 
             linetype = "dashed", 
             color = "#073966") +
  
  # añade estimadores
  geom_pointrange(color = "#418A80") +
  
  # cambia color de fondo
  theme_minimal()
```

## Bibliografía
